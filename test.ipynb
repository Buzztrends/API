{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# environment setup\n",
    "with open(\"./config/.key\", \"r\") as key_file:\n",
    "    keys = list(key_file)\n",
    "\n",
    "for item in keys:\n",
    "    variable, value = item.split(\"=\")[0], \"=\".join(item.split(\"=\")[1:])\n",
    "    os.environ[variable] = value.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML stuff\\buzztrends\\API/ImageGeneration/\n",
      "Creating Indexes from Handbook...\n",
      "Indexes created Successfully\n"
     ]
    }
   ],
   "source": [
    "# Image Generation Module\n",
    "from ImageGeneration.edenai import *\n",
    "\n",
    "# Text Generation Module\n",
    "from TextGeneration.SimpleGeneration import *\n",
    "from TextGeneration.CatelogueGeneration import *\n",
    "from TextGeneration.ReferencePostGeneration import *\n",
    "\n",
    "# Moments Module\n",
    "from Moments.Moments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "from utils.utils import get_llm\n",
    "\n",
    "def generate_content(\n",
    "    company_name: str,\n",
    "    moment: str,\n",
    "    content_type: str,\n",
    "    tone: str,\n",
    "    objective: str,\n",
    "    structure: str,\n",
    "    location: str,\n",
    "    audience: str,\n",
    "    company_info: str,\n",
    "    moment_retriver: VectorStoreRetriever,\n",
    "    model=\"gpt_3_5_chat\"\n",
    "): \n",
    "    if location == \"\":\n",
    "        location = \"No specific target location.\"\n",
    "    \n",
    "    if audience == \"\":\n",
    "        audience = \"No specific target audience. Make it appeal to everyone.\"\n",
    "    \n",
    "    # llm = OpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.5)\n",
    "    print(\"using \", model)\n",
    "    llm = get_llm(model, 0.5)\n",
    "\n",
    "    moment_query = f\"Tell me in detail about {moment}\"\n",
    "    relevant_docs = moment_retriver.get_relevant_documents(moment_query)\n",
    "    moment_context = \"\\n\".join([item.page_content.replace(\"\\n\", \" \") for item in relevant_docs])\n",
    "\n",
    "    # NEW STUFF\n",
    "    moment_query_template = \"\"\"Given the following context, i want you to answer this query: {moment_query}\n",
    "\n",
    "    {moment_context}\n",
    "    \"\"\"\n",
    "    moment_prompt = PromptTemplate(input_variables=[\"moment_query\", \"moment_context\"], template=moment_query_template)\n",
    "    moment_chain = LLMChain(llm=get_llm(\"gpt_3_5_chat\"), prompt=moment_prompt, output_key=\"moment_info\")\n",
    "\n",
    "    # OLD STUFF\n",
    "    # moment_query_template = \"Tell me about {moment_query}. How is it relevant, significant, and important?\"\n",
    "    # moment_prompt = PromptTemplate(input_variables=[\"moment_query\"], template=moment_query_template)\n",
    "    # moment_chain = LLMChain(llm=llm, prompt=moment_prompt, memory=moment_memory, output_key=\"moment_info\")\n",
    "\n",
    "\n",
    "    post_template = \"\"\"Imagine that you are in charge of creating a {content_type}. \n",
    "\n",
    "You are to write a {content_type} about {moment_query}. You must relate it with {company_name}.\n",
    "\n",
    "The content should be targetted towards:\n",
    "Location: {location}\n",
    "Target audience: {audience}.\n",
    "\n",
    "Be creative with the language.\n",
    "\n",
    "Create a title if a {content_type} requires a title\n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "\n",
    "Tone of {content_type}: {tone}\n",
    "Objective of {content_type}: {objective}\n",
    "Structuring of {content_type}: {structure}\n",
    "\n",
    "CONTEXT ON {company_name} and {moment_query} follows: \n",
    "\n",
    "Information about {company_name}:\n",
    "{company_info}\n",
    "\n",
    "Information about {moment_query}:\n",
    "{moment_info}\n",
    "\"\"\"\n",
    "    post_prompt = PromptTemplate(input_variables=[\"company_name\", \"location\", \"audience\", \"moment_query\", \"company_info\", \"moment_info\", \"tone\", \"objective\", \"content_type\", \"structure\"], template=post_template)\n",
    "    post_chain = LLMChain(llm=llm, prompt=post_prompt, output_key=\"post\")\n",
    "\n",
    "    generator_template = \"\"\"Given this post text for a {content_type}: {post}\n",
    "\n",
    "    Tell me what other things can be put in the post. Include description of images, videos, audio, hashtags, etc. as lists, only include elements that are relevant to a {content_type}\"\"\"\n",
    "    generator_prompt = PromptTemplate(input_variables=[\"post\", \"content_type\"], template=generator_template)\n",
    "    generator_chain = LLMChain(llm=llm, prompt=generator_prompt, output_key=\"extras\")\n",
    "\n",
    "    final_chain = SequentialChain(\n",
    "        chains=[moment_chain, post_chain, generator_chain],\n",
    "        input_variables=[\"company_name\", \"company_info\", \"location\", \"audience\", \"moment_query\", \"moment_context\", \"tone\", \"objective\", \"content_type\", \"structure\"],\n",
    "        output_variables=[\"post\", \"extras\"],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return final_chain({\n",
    "        \"company_name\": company_name,\n",
    "        \"company_info\": company_info,\n",
    "        \"moment_query\": moment,\n",
    "        \"moment_context\": moment_context,\n",
    "        \"tone\": tone,\n",
    "        \"objective\": objective,\n",
    "        \"structure\": structure,\n",
    "        \"location\": location,\n",
    "        \"audience\": audience,\n",
    "        \"content_type\": content_type\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment = \"Looking like a wow trend\"\n",
    "content_category = \"Mouth watering food that makes the user crave\"\n",
    "company_name = \"Zomato\"\n",
    "content_type = \"Instagram\"\n",
    "tone = \"casual\"\n",
    "objective = \"entertain\"\n",
    "structure = \"3 to 4 lines\"\n",
    "location = \"Mumbai\"\n",
    "audience = \"Zomato gold subscribers\"\n",
    "company_info = \"\"\"Zomato, a leading global food delivery and restaurant discovery platform, revolutionizes dining experiences. Seamlessly blending technology with gastronomy, it offers a user-friendly app for food enthusiasts. Explore diverse cuisines, read reviews, and conveniently order from local restaurants. Zomato extends beyond delivery, encompassing restaurant reservations, table management, and contactless dining solutions. With keywords like food delivery, restaurant discovery, reviews, reservations, and contactless dining, it caters to diverse culinary needs.\"\"\"\n",
    "country_code = \"IN\"\n",
    "ref_post = \"Mumbai foodies, it's time to upgrade your dining game to a 'WOW' level! With our Zomato Gold subscription, not only will your meals be lip-smacking, but they'll also look Instagram worthy, just like your favorite trend. Let's turn the tables and make every meal a 'Just looking like a wow' moment! #ZomatoGold #WowTrend #Foodie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting information on:  Looking like a wow trend \n",
      "Getting text: https://indianexpress.com/article/trending/trending-in-india/tmc-mp-nusrat-jahan-joins-deepika-padukone-sanya-malhotra-looking-like-a-wow-trend-9009180/\n",
      "Getting text: https://www.business-standard.com/entertainment/how-the-just-looking-like-a-wow-trend-is-taking-over-the-internet-123110800746_1.html\n",
      "Getting text: https://indianexpress.com/article/entertainment/bollywood/deepika-padukones-hilarious-recreation-of-just-looking-like-a-wow-trend-leaves-ranveer-singh-ded-9004204/\n",
      "Getting text: https://www.hindustantimes.com/entertainment/bollywood/nick-jonas-just-looking-like-a-wow-priyanka-chopra-green-saree-jio-world-plaza-101698906579550.html\n",
      "Getting text: https://www.socialmediadissect.com/social-media-dissect/so-beautiful-so-elegant-just-looking-like-a-wow-video-goes-viral/\n",
      "Splitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spliting text: 100%|██████████| 5/5 [00:00<00:00, 555.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building retriver\n"
     ]
    }
   ],
   "source": [
    "moment_context_sitetexts = get_sitetexts(get_related_links(moment.replace(\"Title: \", \"\"), country=country_code, num_results=5))\n",
    "moment_vectorstore, moment_retriver, _, _ = build_vectorstore(moment_context_sitetexts)\n",
    "moment_memory = VectorStoreRetrieverMemory(\n",
    "            retriever=moment_retriver,\n",
    "            input_key=\"moment_query\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\llms\\openai.py:200: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\llms\\openai.py:785: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Post\n",
      " ==================== Mumbai foodies, it's time to upgrade your dining game to a 'WOW' level! With our Zomato Gold subscription, not only will your meals be lip-smacking, but they'll also look Instagram worthy, just like your favorite trend. Let's turn the tables and make every meal a 'Just looking like a wow' moment! #ZomatoGold #WowTrend #Foodie\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = generate_similar_content(\n",
    "    company_name=company_name,\n",
    "    moment=moment,\n",
    "    content_type=content_type,\n",
    "    objective=objective,\n",
    "    location=location,\n",
    "    audience=audience,\n",
    "    company_info=company_info,\n",
    "    moment_retriver=moment_retriver,\n",
    "    ref_post=ref_post,\n",
    "    model=\"gpt_4_high_temp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"post\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using  gpt_4_high_temp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\llms\\openai.py:200: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\llms\\openai.py:785: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = generate_content(\n",
    "    company_name=company_name,\n",
    "    moment=moment,\n",
    "    content_type=content_type,\n",
    "    tone=tone,\n",
    "    objective=objective,\n",
    "    structure=structure,\n",
    "    location=location,\n",
    "    audience=audience,\n",
    "    company_info=company_info,\n",
    "    moment_retriver=moment_retriver,\n",
    "    model=\"gpt_4_high_temp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"Dine like a WOW with Zomato Gold!\"\n",
      "\n",
      "\"Mumbai foodies, it's time to upgrade your dining game to a 'WOW' level! With our Zomato Gold subscription, not only will your meals be lip-smacking, but they'll also look Instagram worthy, just like your favorite trend. Let's turn the tables and make every meal a 'Just looking like a wow' moment! #ZomatoGold #WowTrend #Foodie\"\n"
     ]
    }
   ],
   "source": [
    "print(output[\"post\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
